{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы оптимизации\n",
    "\n",
    "Как было показано на лекции, большинство методов машинного обучения сводятся к поиску параметров, которые минимизируют ошибку на тренировочной выборке:\n",
    "$$\n",
    "\\min_{w} L(w; D)\n",
    "$$\n",
    "Здесь:\n",
    "* $D$ — размеченная обучающая выборка, $\\{x_i, y_i\\}_{i=1}^N$\n",
    "* $L$ — функция потерь\n",
    "* $w$ — настраиваемые веса алгоритма\n",
    "\n",
    "В более общем виде задачу можно записать так:\n",
    "$$\n",
    "\\min_{x} f(x)\n",
    "$$\n",
    "Здесь:\n",
    "* $x$ — вектор значений\n",
    "* $f$ — функция, принимающая вектор в качестве аргумента и выдающая числовое значение.\n",
    "\n",
    "На семинаре рассмотрим подробнее методы минимизации функции, которые рассматривались на лекции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "\n",
    "Для оптимизации возьмем простую функцию $f(x) = x^3 - 2x^2 + 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x: x ** 3 - 2*x ** 2 + 2\n",
    "df = lambda x: 3 * x ** 2 - 4 * x # производная\n",
    "x = np.linspace(-1, 2.5, 1000)\n",
    "plt.plot(x, f(x))\n",
    "plt.xlim([-1, 2.5])\n",
    "plt.ylim([0, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И определим функцию, которая будет оптимизировать функцию $f(x)$ градиентным спуском с заданным постоянным шагом (он же learning rate, темп обучения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_and_plot_steps(learning_rate, x_new=2, compute_learning_rate=None):\n",
    "    x_old = 0\n",
    "    # x_new — точка старта\n",
    "    eps = 0.0001\n",
    "    x_list, y_list = [x_new], [f(x_new)] # инициализируем список координат и значений функций при итерации\n",
    "    \n",
    "    # спускаемся, пока разница между координатами не достигла требуемой точности\n",
    "    i = 0\n",
    "    while abs(x_new - x_old) > eps:\n",
    "        # обновляем значение темпа обучения, если нам задана функция для этого\n",
    "        if compute_learning_rate is not None:\n",
    "            learning_rate = compute_learning_rate(i, learning_rate)\n",
    "            \n",
    "        x_old = x_new\n",
    "        # считаем направление спуска\n",
    "        # делаем шаг\n",
    "        # Ваш код здесь!\n",
    "        \n",
    "        # запоминаем очередной шаг минимизации\n",
    "        x_list.append(x_new)\n",
    "        y_list.append(f(x_new))\n",
    "        i += 1\n",
    "        \n",
    "    print(\"Найденный локальный минимум:\", x_new)\n",
    "    print(\"Количество шагов:\", len(x_list))\n",
    "    \n",
    "    plt.figure(figsize=[10,3])\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(x_list, y_list, c=\"r\", edgecolors='k')\n",
    "    plt.plot(x_list, y_list, c=\"r\")\n",
    "    plt.plot(x, f(x), c=\"b\")\n",
    "    plt.xlim([-1,2.5])\n",
    "    plt.ylim([0,3])\n",
    "    plt.title(\"Descent trajectory\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(x_list,y_list,c=\"r\", edgecolors='k')\n",
    "    plt.plot(x_list,y_list,c=\"r\")\n",
    "    plt.plot(x,f(x), c=\"b\")\n",
    "    plt.xlim([1.2,2.1])\n",
    "    plt.ylim([0,3])\n",
    "    plt.title(\"Descent trajectory (zoomed in)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оптимизацию с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем шаг побольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что, если взять 0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Застопорились в нуле, т.к. нашли точный локальный максимум. В нем производная равна нулю и мы никуда не можем сдвинуться. А если взять 0.49?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что, если взять 0.51?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы улетели далеко влево. Это можно понять, распечатав значения x_new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмём маленький шаг. Например, 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.01?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем меньше шаг, тем медленнее мы идём к минимум (и можем вдобавок застрять по пути). Чем больше темп обучения, тем большие расстояния мы перепрыгиваем (и имеем гипотетическую возможность найти минимум получше). Хорошая стратегия — начинать с достаточно большого шага (чтобы хорошо попутешествовать по функции), а потом постепенно его уменьшать, чтобы стабилизировать процесс обучения в каком-то локальном минимуме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь будем изменять шаг динамически:\n",
    "$lr(i + 1) = lr(i) * 0.9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_learning_rate(i, prev_lr):\n",
    "    return prev_lr * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.4, compute_learning_rate=compute_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если сравнивать с постоянным темпом обучения, то мы нашли минимум в 2 раза быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize_and_plot_steps(0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это, конечно, искуственный пример, но такая же идея используются для обучения алгоритмов машинного обучения с миллионами параметров, функции потерь которых имеют очень сложную структуру и не поддаются визуализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка линейной регрессии с помощью градиентного спуска\n",
    "\n",
    "Рассмотрим теперь реальные данные и попробуем использовать градиентный спуск для решения задачи линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл food_trucks.txt. В нём два столбца значений — количество жителей в городе и доход грузовика с уличной едой в этом городе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "food = pd.read_csv('food_trucks.txt',names = ['population', 'income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте данные. По оси X — население города, по оси Y — доход грузовика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2ab85f2390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2abcf58f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(food.population,food.income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним функцию потерь линейной регрессии:\n",
    "$$\n",
    "L(w) = \\frac{1}{2m} \\sum_{i=1}^m (h(x^i, w) - y^i)^2\n",
    "$$\n",
    "Здесь $h(x, w) = w^Tx = w_0 + w_1 x_1$ (предполагается, что $x_0=1$ — дополнительный признак для удобства).\n",
    "$(x^i, y^i)$ — i-ый объект выборки.\n",
    "Тогда правило обновления весов будет выглядеть следующим образом:\n",
    "$$\n",
    "w_j = w_j - \\eta \\cdot \\frac{1}{m}\\sum_{i=1}^m(h(x^i, w) - y^i) x^i_j.\n",
    "$$\n",
    "Здесь $x^i_j$ — j-ая компонента i-ого объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите функцию потерь и её производную. Эти функции имеют один аргумент — вектор весов $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию минимизации $L(w)$ с помощью градиентного спуска, аналогичную optimize_and_plot_steps. На вход она принимает параметры обучения (темп обучения и начальное значение весов), оптимизирует итеративно функцию потерь, печатает итерации и визуализирует уменьшение функции потерь и найденное решение. Запустите функцию с постоянным темпом обучения и прокомментируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измените функцию минимизации так, чтобы темп обучения мог меняться динамически, аналогично примеру выше. Запустите функцию и прокомментируйте результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия с батч-оптимизацией\n",
    "\n",
    "Теперь рассмотрим случай, когда данных в выборке много. В таких случаях используется стохастическая или батч-оптимизация. Первая состоит в том, что на каждом шаге итерации берется один объект, вторая — в том, что берется некоторое небольшое фиксированное количество объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные из файла space_ga.csv и нормализуйте их. Мы будем предсказывать первый столбец по шести остальным. Эти данные получены с выборов в США в 1980 году. Подробнее о столбцах можно прочитать тут: http://mldata.org/repository/data/viewslug/statlib-20050214-space_ga/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы могли заметить, датасет больше предыдущего. На нём мы попробуем батч-оптимизацию.\n",
    "\n",
    "Измените функцию минимизации так, чтобы на вход они принимала дополнительный параметр — размер батча. Для простоты проверки рекомендуется изменять копию функции, реализованной выше, с измененным именем. Запустите функцию при разных размерах батча. Прокомментируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
